{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> One Layer Neural Network </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Functions for pushing numbers forward </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    " \n",
    "# TODO \n",
    "# function that generates weights and decides number of hidden layers\n",
    "\n",
    "# give it the weight and inputs and it will calculate the results\n",
    "def feedInputsForward(inputs,weights):\n",
    "    outputArr = []\n",
    "    \n",
    "    # if there are multiple hidden layers, you need to have a set of weights for each input to HL connection\n",
    "    if(weights.ndim > 1):\n",
    "        for each in weights:\n",
    "            outputArr.append(gradiantDescentFormula(np.dot(each,inputs)))\n",
    "        return np.array(outputArr)\n",
    "    \n",
    "    # if there is only one output/hidden layer, just do the dot product of the 1-d arrays\n",
    "    else:\n",
    "        outputArr.append(gradiantDescentFormula(np.dot(inputs,weights)))\n",
    "        return np.array(outputArr)\n",
    "\n",
    "\n",
    "# gradiant descent is defined as 1 / (1 + e^(-x))\n",
    "# this formula does that though imperfectly\n",
    "def gradiantDescentFormula(x):\n",
    "    return (1/(1 + (math.e ** (-x)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Backpropagation Error Calculation Functions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# calculates the total error in the network i.e. difference betweeen target and output\n",
    "def totalError(target, y):\n",
    "    return (1/2) * ((target - y) ** 2)\n",
    "\n",
    "# calculates error for the output unit y\n",
    "def errorOfY(target,y):\n",
    "    return y * (1 - y) * (target - y)\n",
    "\n",
    "# calculates the error for each hidden node\n",
    "# PARAM: hl is the value calculated for that hidden layer\n",
    "# PARAM: weight is the weight of that specified connection\n",
    "# PARAM: error of Y is the error of the output unit y\n",
    "def hiddenNodeError(hl,weight, errorOfY):\n",
    "    return hl * (1 - hl) * (weight * errorOfY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Learning Functions </h2>\n",
    "This one is more complicated so I will be doing a lot of documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that calculates the new weight for the HL to output\n",
    "# PARAM: currentWeight is the weight of the connection between the hidden node and the output\n",
    "# PARAM: learningFactor is an overall value for the network\n",
    "# PARAM: errorOfY is the error for the output unit y\n",
    "# PARAM: hlValue is the value at the HL\n",
    "def updateWeightOfHLToY(currentWeight,learningFactor,errorOfY,hlValue):\n",
    "    return currentWeight + (learningFactor * errorOfY * hlValue)\n",
    "\n",
    "# this is the function that calculates the new weight for the input to HL\n",
    "# PARAM: currentWeight is the weight of the connection between the input and the hidden node\n",
    "# PARAM: learningFactor is an overall value for the network\n",
    "# PARAM: errorOfHL is the error of the hidden node\n",
    "# PARAM: inputVal is the value of input\n",
    "def updateWeightofInputToHL(currentWeight,learningFactor,errorOfHL,inputVal):\n",
    "    return currentWeight + (learningFactor * errorOfHL * inputVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Architecture Functions </h2>\n",
    " Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[1.         0.81757448 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generates num of hidden nodes\n",
    "def howManyHN(numInputs, numOutputs):\n",
    "    HN = (2/3) * (numInputs + numOutputs)\n",
    "    return round(HN,1)\n",
    "\n",
    "# generates weights for inputs to HL\n",
    "def generateWeightsForInputToHL(numInputs,numH):\n",
    "    # todo once Erin gets back to me\n",
    "    return 0\n",
    "\n",
    "\n",
    "# TODO: figure out how to do it with a lot lot more data; it currently assumes that you are only giving it\n",
    "#       a 1-D array on inputs, it would be pretty easy to modify that but for now I will leave it\n",
    "    \n",
    "def neuralNetwork(inputArray,numOutputs,bias):\n",
    "    # calculate how many hidden nodes\n",
    "    numHN = howManyHN(len(inputArray),numOutputs)\n",
    "    \n",
    "    # TODO: Generate Random Weights; for now I am hard coding weights I know the results of\n",
    "    #       to verify it is working\n",
    "    \n",
    "    # Input to HL Weights\n",
    "    inputToHLW = [[1,1,0.5],[1,-1,2]]\n",
    "    numpyinputTOHLW = np.array(HLW)\n",
    "    \n",
    "    # HL to Out Weights \n",
    "    HLToOutW = [1,1.5,-1]\n",
    "    numpyHlToOutW = np.array(hlToOutW)\n",
    "    \n",
    "    \n",
    "    # array for hidden node values\n",
    "    hiddenNodeValues = []\n",
    "    \n",
    "    # array for the results\n",
    "    results = []\n",
    "    \n",
    "    # convert inputArray to a numpy Array if needed and append bias\n",
    "    inputArray.insert(0,bias)\n",
    "    \n",
    "    if not isinstance(inputArray, np.ndarray):\n",
    "        numpyInput = np.array(inputArray)\n",
    "    else:\n",
    "        numpyInput = inputArray\n",
    "    \n",
    "    # get the hidden node values\n",
    "    hiddenNodeValues = feedInputsForward(numpyInputs,numpyHLW)\n",
    "    \n",
    "    # put bias back in\n",
    "    hiddenNodeValues = np.insert(hiddenNodeValues,0,bias)\n",
    "    \n",
    "    # calculate results\n",
    "    results = feedInputsForward(hiddenNodeValues,numpyHlToOutW)\n",
    "    \n",
    "    # Finished and tested up to backpropogation \n",
    "    \"\"\"\n",
    "    print(hiddenNodeValues)\n",
    "    print(results)\n",
    "    print(type(hiddenNodeValues))\n",
    "    print(type(results))\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    \n",
    "inputs = [0,1]   \n",
    "neuralNetwork(inputs,1,1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Main </h3> \n",
    "This is what I used for testing while I was buidling the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 1: 0.8175744761936437\n",
      "Hidden Layer 2: 0.9525741268224331\n",
      "y = 0.7813904309473313\n",
      "Total Error: 0.023895071840696763\n",
      "Error of Y: 0.037342760966238966\n",
      "HL1 Error: 0.008354310462937586\n",
      "HL2 Error: -0.001687021205584568\n",
      "Updated Weight for Bias to Y: 1.0152652441182985\n",
      "Updated Weight for input1 to h1 Weight: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# intital varaibles for back propigation later\n",
    "HL1 = 0\n",
    "HL2 = 0\n",
    "y = 0\n",
    "\n",
    "# all the starting weights for the input to hidden layer\n",
    "# start with bias then H1-1 to HL-n \n",
    "bias = 1\n",
    "HLW = [[1,1,0.5],[1,-1,2]]\n",
    "numpyHLW = np.array(HLW)\n",
    "\n",
    "# set the inputs and bias\n",
    "inputs = [bias,0,1]\n",
    "numpyInputs = np.array(inputs)\n",
    "\n",
    "\n",
    "# set the inputs for the hidden to output layer\n",
    "numpyHlToOut = feedInputsForward(numpyInputs,numpyHLW)\n",
    "\n",
    "# record the results\n",
    "HL1 = numpyHlToOut[0]\n",
    "HL2 = numpyHlToOut[1]\n",
    "\n",
    "# put bias back in at the front\n",
    "numpyHlToOut = np.insert(numpyHlToOut,0,bias)\n",
    "\n",
    "\n",
    "# all the weights for the hidden to output layer\n",
    "hlToOutW = [1,1.5,-1]\n",
    "numpyHlToOutW = np.array(hlToOutW)\n",
    "\n",
    "# get the results\n",
    "results = feedInputsForward(numpyHlToOut,numpyHlToOutW)\n",
    "\n",
    "# record the results\n",
    "y = results[0]\n",
    "\n",
    "\n",
    "# print the results\n",
    "print(\"Hidden Layer 1: %s\" % HL1)\n",
    "print(\"Hidden Layer 2: %s\" % HL2)\n",
    "print(\"y = %s\" % y)\n",
    "\n",
    "\n",
    "# start of backpropogation part\n",
    "\n",
    "totalE = totalError(1,y)\n",
    "print(\"Total Error: %s\" % totalE)\n",
    "\n",
    "yError = errorOfY(1,y)\n",
    "print(\"Error of Y: %s\" % yError)\n",
    "\n",
    "h1Error = hiddenNodeError(HL1,numpyHlToOutW[1],yError)\n",
    "h2Error = hiddenNodeError(HL2,numpyHlToOutW[2],yError)\n",
    "print(\"HL1 Error: %s\" % h1Error)\n",
    "print(\"HL2 Error: %s\" % h2Error)\n",
    "\n",
    "# calculating updated weights for HL to Y\n",
    "\n",
    "# bias\n",
    "newBiasToY = updateWeightOfHLToY(numpyHlToOutW[0],0.5,yError,HL1)\n",
    "print(\"Updated Weight for Bias to Y: %s\" % newBiasToY)\n",
    "\n",
    "# calulating error for input to HL\n",
    "\n",
    "# new input 1 to h1 weight \n",
    "newInput1toH1 = updateWeightofInputToHL(numpyHLW[0][1],0.5,h1Error,inputs[1])\n",
    "print(\"Updated Weight for input1 to h1 Weight: %s\" % newInput1toH1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
